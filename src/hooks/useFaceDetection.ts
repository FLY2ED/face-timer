import { useState, useEffect, useRef, useCallback } from "react";
import * as faceapi from "@vladmandic/face-api";
import { toast } from "sonner";

// 1. ì¸í„°í˜ì´ìŠ¤ ì •ì˜ ì œê±° ë° íƒ€ì… ë³„ì¹­ ì‚¬ìš©
// type BoxData extends faceapi.Box {}
// type DetectionData extends faceapi.FaceDetection {}
// type LandmarksData extends faceapi.FaceLandmarks68 {}

// FullFaceDescriptionType ì •ì˜ ìˆ˜ì •
type FullFaceDescriptionType = {
  detection: faceapi.FaceDetection;    // faceapi.FaceDetection ì§ì ‘ ì‚¬ìš©
  landmarks: faceapi.FaceLandmarks68;  // faceapi.FaceLandmarks68 ì§ì ‘ ì‚¬ìš©
  expressions: faceapi.FaceExpressions;
};

export interface FaceAnalysisResult {
  isDrowsy: boolean;
  isAttentive: boolean;
  emotion: string;
  ear: number;
  mar: number; // Mouth Aspect Ratio
  gazeDirection: 'center' | 'left' | 'right' | 'up' | 'down' | 'unknown';
  headPose: {
    yaw: number;    // ì¢Œìš° íšŒì „
    pitch: number;  // ìƒí•˜ íšŒì „
    roll: number;   // ê¸°ìš¸ê¸°
  };
  blinkRate: number;
  attentionScore: number; // 0-100 ì ìˆ˜
  fatigueLevel: 'low' | 'medium' | 'high';
  confidence: number;
}

interface UseFaceDetectionProps {
  videoRef: React.RefObject<HTMLVideoElement>;
  canvasRef: React.RefObject<HTMLCanvasElement>;
  onFaceDetected: (result?: FaceAnalysisResult) => void;
  onFaceNotDetected: () => void;
  showPreview: boolean;
}

// ê³ ê¸‰ EAR ê³„ì‚° (ë” ì •í™•í•œ ëˆˆ ê°ê¹€ ë¹„ìœ¨)
function computeAdvancedEAR(eye: faceapi.Point[]): number {
  if (eye.length < 6) {
    console.warn("âš ï¸ EAR ê³„ì‚°: ëˆˆ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ ë¶€ì¡±", { points: eye.length });
    return 0.25; // ê¸°ë³¸ê°’
  }
  
  const euclideanDistance = (a: faceapi.Point, b: faceapi.Point) => 
    Math.sqrt(Math.pow(a.x - b.x, 2) + Math.pow(a.y - b.y, 2));
  
  // ìˆ˜ì§ ê±°ë¦¬ë“¤
  const vertical1 = euclideanDistance(eye[1], eye[5]);
  const vertical2 = euclideanDistance(eye[2], eye[4]);
  
  // ìˆ˜í‰ ê±°ë¦¬
  const horizontal = euclideanDistance(eye[0], eye[3]);
  
  // EAR ê³„ì‚° (ë” ì •êµí•œ ê³µì‹)
  const ear = (vertical1 + vertical2) / (2.0 * horizontal);
  
  // ë””ë²„ê¹…: ê°€ë”ì”© EAR ê³„ì‚° ê³¼ì • ë¡œê·¸ (5% í™•ë¥ )
  if (Math.random() < 0.05) {
    console.log("ğŸ‘ï¸ EAR ê³„ì‚°:", {
      vertical1: vertical1.toFixed(2),
      vertical2: vertical2.toFixed(2),
      horizontal: horizontal.toFixed(2),
      ear: ear.toFixed(3),
      eyePoints: eye.length
    });
  }
  
  return ear;
}

// MAR ê³„ì‚° (ì… ë²Œë¦¼ ë¹„ìœ¨ - í•˜í’ˆ ê°ì§€ìš©)
function computeMAR(mouth: faceapi.Point[]): number {
  if (mouth.length < 20) return 0; // ê¸°ë³¸ê°’
  
  const euclideanDistance = (a: faceapi.Point, b: faceapi.Point) => 
    Math.sqrt(Math.pow(a.x - b.x, 2) + Math.pow(a.y - b.y, 2));
  
  // ì… ì„¸ë¡œ ê±°ë¦¬ë“¤
  const vertical1 = euclideanDistance(mouth[13], mouth[19]); // ìƒë‹¨-í•˜ë‹¨
  const vertical2 = euclideanDistance(mouth[14], mouth[18]); // ì¤‘ì•™ ìƒ-í•˜
  const vertical3 = euclideanDistance(mouth[15], mouth[17]); // ë‚´ë¶€ ìƒ-í•˜
  
  // ì… ê°€ë¡œ ê±°ë¦¬
  const horizontal = euclideanDistance(mouth[12], mouth[16]); // ì¢Œ-ìš° ëª¨ì„œë¦¬
  
  return (vertical1 + vertical2 + vertical3) / (3.0 * horizontal);
}

// ë¨¸ë¦¬ ìì„¸ ì¶”ì • (Head Pose Estimation)
function estimateHeadPose(landmarks: faceapi.FaceLandmarks68): { yaw: number; pitch: number; roll: number } {
  // ì£¼ìš” ì–¼êµ´ í¬ì¸íŠ¸ë“¤
  const noseTip = landmarks.getNose()[3]; // ì½”ë
  const chin = landmarks.getJawOutline()[8]; // í„±
  const leftEyeCorner = landmarks.getLeftEye()[0]; // ì™¼ìª½ ëˆˆ ëª¨ì„œë¦¬
  const rightEyeCorner = landmarks.getRightEye()[3]; // ì˜¤ë¥¸ìª½ ëˆˆ ëª¨ì„œë¦¬
  const leftMouth = landmarks.getMouth()[0]; // ì… ì™¼ìª½
  const rightMouth = landmarks.getMouth()[6]; // ì… ì˜¤ë¥¸ìª½
  
  // Yaw (ì¢Œìš° íšŒì „) ê³„ì‚°
  const eyeCenter = {
    x: (leftEyeCorner.x + rightEyeCorner.x) / 2,
    y: (leftEyeCorner.y + rightEyeCorner.y) / 2
  };
  const noseToEyeCenter = noseTip.x - eyeCenter.x;
  const yaw = Math.atan2(noseToEyeCenter, Math.abs(leftEyeCorner.x - rightEyeCorner.x)) * (180 / Math.PI);
  
  // Pitch (ìƒí•˜ íšŒì „) ê³„ì‚°
  const eyeToNose = noseTip.y - eyeCenter.y;
  const noseToMouth = Math.abs(noseTip.y - (leftMouth.y + rightMouth.y) / 2);
  const pitch = Math.atan2(eyeToNose, noseToMouth) * (180 / Math.PI);
  
  // Roll (ê¸°ìš¸ê¸°) ê³„ì‚°
  const eyeSlope = (rightEyeCorner.y - leftEyeCorner.y) / (rightEyeCorner.x - leftEyeCorner.x);
  const roll = Math.atan(eyeSlope) * (180 / Math.PI);
  
  return { yaw, pitch, roll };
}

// ê³ ê¸‰ ì‹œì„  ì¶”ì  ì•Œê³ ë¦¬ì¦˜
function advancedGazeEstimation(landmarks: faceapi.FaceLandmarks68): 'center' | 'left' | 'right' | 'up' | 'down' | 'unknown' {
  const leftEye = landmarks.getLeftEye();
  const rightEye = landmarks.getRightEye();
  const nose = landmarks.getNose();
  
  if (!leftEye || !rightEye || !nose) return 'unknown';
  
  // ëˆˆë™ì ì¤‘ì‹¬ ì¶”ì •
  const leftEyeCenter = {
    x: leftEye.reduce((sum, p) => sum + p.x, 0) / leftEye.length,
    y: leftEye.reduce((sum, p) => sum + p.y, 0) / leftEye.length
  };
  
  const rightEyeCenter = {
    x: rightEye.reduce((sum, p) => sum + p.x, 0) / rightEye.length,
    y: rightEye.reduce((sum, p) => sum + p.y, 0) / rightEye.length
  };
  
  const noseTip = nose[3];
  const eyeCenter = {
    x: (leftEyeCenter.x + rightEyeCenter.x) / 2,
    y: (leftEyeCenter.y + rightEyeCenter.y) / 2
  };
  
  // ì‹œì„  ë²¡í„° ê³„ì‚°
  const gazeVector = {
    x: noseTip.x - eyeCenter.x,
    y: noseTip.y - eyeCenter.y
  };
  
  // ì„ê³„ê°’ ì„¤ì • (ë” ì •í™•í•œ íŒë‹¨)
  const horizontalThreshold = 8;
  const verticalThreshold = 6;
  
  if (Math.abs(gazeVector.x) > horizontalThreshold) {
    return gazeVector.x > 0 ? 'right' : 'left';
  }
  if (Math.abs(gazeVector.y) > verticalThreshold) {
    return gazeVector.y > 0 ? 'down' : 'up';
  }
  
  return 'center';
}

// ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜
function calculateAttentionScore(
  ear: number, 
  mar: number, 
  headPose: { yaw: number; pitch: number; roll: number },
  gazeDirection: string,
  blinkRate: number
): number {
  let score = 100;
  
  // EAR ê¸°ë°˜ ê°ì  (ëˆˆ ê°ê¹€)
  if (ear < 0.15) score -= 40; // ì‹¬ê°í•œ ì¡¸ìŒ
  else if (ear < 0.20) score -= 25; // ì¤‘ê°„ ì¡¸ìŒ
  else if (ear < 0.25) score -= 10; // ê°€ë²¼ìš´ ì¡¸ìŒ
  
  // MAR ê¸°ë°˜ ê°ì  (í•˜í’ˆ)
  if (mar > 0.7) score -= 30; // í•˜í’ˆ
  else if (mar > 0.5) score -= 15; // ì… ë²Œë¦¼
  
  // ë¨¸ë¦¬ ìì„¸ ê¸°ë°˜ ê°ì 
  const totalHeadMovement = Math.abs(headPose.yaw) + Math.abs(headPose.pitch) + Math.abs(headPose.roll);
  if (totalHeadMovement > 45) score -= 25; // ì‹¬í•œ ê³ ê°œ ì›€ì§ì„
  else if (totalHeadMovement > 25) score -= 15; // ì¤‘ê°„ ê³ ê°œ ì›€ì§ì„
  
  // ì‹œì„  ë°©í–¥ ê¸°ë°˜ ê°ì 
  if (gazeDirection !== 'center') score -= 20;
  
  // ê¹œë¹¡ì„ ë¹ˆë„ ê¸°ë°˜ ê°ì  (ê°œì„ ëœ ë¡œì§)
  if (blinkRate < 8) score -= 35; // ë§¤ìš° ì¡¸ë¦¼ (ì‹¬ê°í•œ ê¹œë¹¡ì„ ë¶€ì¡±)
  else if (blinkRate < 12) score -= 20; // ì¡¸ë¦¼ (ê¹œë¹¡ì„ ë¶€ì¡±)
  else if (blinkRate > 35) score -= 25; // ë§¤ìš° ê¸´ì¥/ìŠ¤íŠ¸ë ˆìŠ¤ (ê³¼ë„í•œ ê¹œë¹¡ì„)
  else if (blinkRate > 25) score -= 10; // ì•½ê°„ ê¸´ì¥ (ë†’ì€ ê¹œë¹¡ì„)
  // 12-25íšŒ/ë¶„ì€ ì •ìƒ ë²”ìœ„ë¡œ ê°ì í•˜ì§€ ì•ŠìŒ
  
  return Math.max(0, Math.min(100, score));
}

// í”¼ë¡œë„ ë ˆë²¨ íŒë‹¨
function assessFatigueLevel(attentionScore: number, ear: number, consecutiveDrowsyFrames: number): 'low' | 'medium' | 'high' {
  if (attentionScore < 30 || ear < 0.15 || consecutiveDrowsyFrames > 10) {
    return 'high';
  } else if (attentionScore < 60 || ear < 0.20 || consecutiveDrowsyFrames > 5) {
    return 'medium';
  }
  return 'low';
}

export const useFaceDetection = ({
  videoRef,
  canvasRef,
  onFaceDetected,
  onFaceNotDetected,
  showPreview,
}: UseFaceDetectionProps) => {
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [isDetecting, setIsDetecting] = useState(false);
  const [isCameraReady, setIsCameraReady] = useState(false);
  const [lastDetectionTime, setLastDetectionTime] = useState(Date.now());
  const [modelLoadingError, setModelLoadingError] = useState<string | null>(null);
  
  const [blinkHistory, setBlinkHistory] = useState<number[]>([]);
  const [consecutiveDrowsyFrames, setConsecutiveDrowsyFrames] = useState(0);
  const [earHistory, setEarHistory] = useState<number[]>([]);
  const [attentionHistory, setAttentionHistory] = useState<number[]>([]);
  
  // ê¹œë¹¡ì„ ê°ì§€ë¥¼ ìœ„í•œ ìƒíƒœ ì¶”ê°€
  const [blinkTimestamps, setBlinkTimestamps] = useState<number[]>([]);
  const [isEyeClosed, setIsEyeClosed] = useState(false);
  const [lastBlinkTime, setLastBlinkTime] = useState(0);
  
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const frameCountRef = useRef(0);
  const animationFrameRef = useRef<number | null>(null);
  
  const lastFullDetectionsRef = useRef<FullFaceDescriptionType[]>([]); 
  const smoothedBoxesRef = useRef<Map<number, faceapi.Rect>>(new Map());
  const isDetectingRef = useRef(false);

  // ê¹œë¹¡ì„ ê°ì§€ í•¨ìˆ˜
  const detectBlink = useCallback((ear: number): number => {
    const currentTime = Date.now();
    const BLINK_THRESHOLD = 0.25; // ì„ê³„ê°’ì„ 0.21ì—ì„œ 0.25ë¡œ ìƒí–¥ ì¡°ì •
    const MIN_BLINK_DURATION = 100; // ìµœì†Œ ì§€ì†ì‹œê°„ì„ 80msì—ì„œ 100msë¡œ ì¡°ì •
    const MAX_BLINK_DURATION = 500; // ìµœëŒ€ ì§€ì†ì‹œê°„ì„ 400msì—ì„œ 500msë¡œ ì¡°ì •
    
    // ë””ë²„ê¹…: EAR ê°’ê³¼ ìƒíƒœ ë¡œê¹… (10í”„ë ˆì„ë§ˆë‹¤)
    if (Math.random() < 0.1) { // 10% í™•ë¥ ë¡œ ë¡œê·¸ ì¶œë ¥
      console.log("ğŸ‘ï¸ ê¹œë¹¡ì„ ê°ì§€:", {
        ear: ear.toFixed(3),
        threshold: BLINK_THRESHOLD,
        isEyeClosed,
        timeSinceLastBlink: currentTime - lastBlinkTime
      });
    }
    
    // ëˆˆì´ ê°ê¸´ ìƒíƒœ ê°ì§€
    if (ear < BLINK_THRESHOLD && !isEyeClosed) {
      console.log("ğŸ‘ï¸ ëˆˆ ê°ê¹€ ê°ì§€:", { ear: ear.toFixed(3), time: currentTime });
      setIsEyeClosed(true);
      setLastBlinkTime(currentTime);
    }
    // ëˆˆì´ ë‹¤ì‹œ ëœ¬ ìƒíƒœ ê°ì§€ (ê¹œë¹¡ì„ ì™„ë£Œ)
    else if (ear >= BLINK_THRESHOLD && isEyeClosed) {
      const blinkDuration = currentTime - lastBlinkTime;
      console.log("ğŸ‘ï¸ ëˆˆ ëœ¸ ê°ì§€:", { 
        ear: ear.toFixed(3), 
        duration: blinkDuration,
        isValid: blinkDuration >= MIN_BLINK_DURATION && blinkDuration <= MAX_BLINK_DURATION
      });
      
      // ìœ íš¨í•œ ê¹œë¹¡ì„ì¸ì§€ í™•ì¸ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•Šì€ì§€)
      if (blinkDuration >= MIN_BLINK_DURATION && blinkDuration <= MAX_BLINK_DURATION) {
        console.log("âœ… ìœ íš¨í•œ ê¹œë¹¡ì„ ê°ì§€ë¨!", { duration: blinkDuration });
        setBlinkTimestamps(prev => {
          const newTimestamps = [...prev, currentTime];
          const filtered = newTimestamps.filter(timestamp => currentTime - timestamp <= 60000);
          console.log("ğŸ“Š ê¹œë¹¡ì„ ê¸°ë¡ ì—…ë°ì´íŠ¸:", { 
            newCount: filtered.length,
            recentBlinks: filtered.slice(-5)
          });
          return filtered;
        });
      } else {
        console.log("âŒ ë¬´íš¨í•œ ê¹œë¹¡ì„:", { 
          duration: blinkDuration,
          tooShort: blinkDuration < MIN_BLINK_DURATION,
          tooLong: blinkDuration > MAX_BLINK_DURATION
        });
      }
      
      setIsEyeClosed(false);
    }
    
    // í˜„ì¬ 1ë¶„ê°„ ê¹œë¹¡ì„ íšŸìˆ˜ ê³„ì‚°
    const recentBlinks = blinkTimestamps.filter(timestamp => currentTime - timestamp <= 60000);
    
    // ê¹œë¹¡ì„ ì¹´ìš´íŠ¸ ë³€ê²½ ì‹œ ë¡œê·¸
    if (recentBlinks.length !== blinkTimestamps.length) {
      console.log("ğŸ“ˆ ê¹œë¹¡ì„ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸:", { 
        currentCount: recentBlinks.length,
        totalRecords: blinkTimestamps.length
      });
    }
    
    return recentBlinks.length;
  }, [isEyeClosed, lastBlinkTime, blinkTimestamps]);

  // ê¹œë¹¡ì„ ê¸°ë°˜ ì¡¸ìŒ íŒë‹¨
  const assessDrowsinessFromBlinks = useCallback((blinksPerMinute: number): { isDrowsyFromBlinks: boolean; blinkStatus: string } => {
    if (blinksPerMinute < 8) {
      return { isDrowsyFromBlinks: true, blinkStatus: 'ë§¤ìš° ì¡¸ë¦¼' };
    } else if (blinksPerMinute < 12) {
      return { isDrowsyFromBlinks: true, blinkStatus: 'ì¡¸ë¦¼' };
    } else if (blinksPerMinute <= 25) {
      return { isDrowsyFromBlinks: false, blinkStatus: 'ì •ìƒ' };
    } else if (blinksPerMinute <= 35) {
      return { isDrowsyFromBlinks: false, blinkStatus: 'ì•½ê°„ ê¸´ì¥' };
    } else {
      return { isDrowsyFromBlinks: false, blinkStatus: 'ë§¤ìš° ê¸´ì¥' };
    }
  }, []);

  useEffect(() => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) return;

    const updateCanvasGeometry = () => {
      console.log("ğŸ¨ updateCanvasGeometry í˜¸ì¶œë¨:", {
        videoWidth: video.videoWidth,
        videoHeight: video.videoHeight,
        clientWidth: video.clientWidth,
        clientHeight: video.clientHeight,
        readyState: video.readyState,
        currentTime: video.currentTime
      });

      if (!video.videoWidth || !video.videoHeight) {
        console.warn("âš ï¸ ë¹„ë””ì˜¤ ì›ë³¸ í¬ê¸° ì •ë³´ ì—†ìŒ, ëŒ€ê¸° ì¤‘...");
        setIsCameraReady(false);
        return;
      }

      if (video.clientWidth === 0 || video.clientHeight === 0) {
        console.warn("âš ï¸ ë¹„ë””ì˜¤ ìš”ì†Œ í¬ê¸° ì •ë³´ ì—†ìŒ, ëŒ€ê¸° ì¤‘...");
        setIsCameraReady(false);
        return;
      }

      const devicePixelRatio = window.devicePixelRatio || 1;
      const videoClientWidth = video.clientWidth;
      const videoClientHeight = video.clientHeight;
      const videoAspectRatio = video.videoWidth / video.videoHeight;
      const clientAspectRatio = videoClientWidth / videoClientHeight;
      let renderedVideoWidth, renderedVideoHeight, offsetX, offsetY;

      if (videoAspectRatio > clientAspectRatio) {
        renderedVideoWidth = videoClientWidth;
        renderedVideoHeight = videoClientWidth / videoAspectRatio;
        offsetX = 0;
        offsetY = (videoClientHeight - renderedVideoHeight) / 2;
      } else {
        renderedVideoHeight = videoClientHeight;
        renderedVideoWidth = videoClientHeight * videoAspectRatio;
        offsetY = 0;
        offsetX = (videoClientWidth - renderedVideoWidth) / 2;
      }

      console.log("âœ… ìº”ë²„ìŠ¤ ì§€ì˜¤ë©”íŠ¸ë¦¬ ê³„ì‚° ì™„ë£Œ:", {
        ë¹„ë””ì˜¤ì›ë³¸: `${video.videoWidth}x${video.videoHeight}`,
        ë¹„ë””ì˜¤ìš”ì†Œ: `${videoClientWidth}x${videoClientHeight}`,
        ë Œë”ë§ì˜ì—­: `${Math.round(renderedVideoWidth)}x${Math.round(renderedVideoHeight)}`,
        ì˜¤í”„ì…‹: `${Math.round(offsetX)}, ${Math.round(offsetY)}`,
        ë¹„ìœ¨ì°¨ì´: videoAspectRatio > clientAspectRatio ? 'ê°€ë¡œë ˆí„°ë°•ìŠ¤' : 'ì„¸ë¡œë ˆí„°ë°•ìŠ¤'
      });

      canvas.style.width = `${renderedVideoWidth}px`;
      canvas.style.height = `${renderedVideoHeight}px`;
      canvas.style.left = `${offsetX}px`;
      canvas.style.top = `${offsetY}px`;
      canvas.style.position = 'absolute';

      canvas.width = Math.round(renderedVideoWidth * devicePixelRatio);
      canvas.height = Math.round(renderedVideoHeight * devicePixelRatio);

      const ctx = canvas.getContext('2d');
      if (ctx) {
        ctx.setTransform(devicePixelRatio, 0, 0, devicePixelRatio, 0, 0);
      }
      
      faceapi.matchDimensions(canvas, { width: renderedVideoWidth, height: renderedVideoHeight });
      
      console.log("âœ… ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ ì„¤ì •");
      setIsCameraReady(true);
    };

    const observer = new ResizeObserver(updateCanvasGeometry);
    observer.observe(video);
    video.addEventListener('loadedmetadata', updateCanvasGeometry);
    video.addEventListener('play', updateCanvasGeometry);
    video.addEventListener('resize', updateCanvasGeometry);
    
    // ì¶”ê°€: ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë³€ê²½ ì‹œì—ë„ ì§€ì˜¤ë©”íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
    video.addEventListener('loadeddata', updateCanvasGeometry);

    if (video.videoWidth && video.videoHeight && video.clientWidth && video.clientHeight) {
      updateCanvasGeometry();
    }

    return () => {
      observer.unobserve(video);
      observer.disconnect();
      video.removeEventListener('loadedmetadata', updateCanvasGeometry);
      video.removeEventListener('play', updateCanvasGeometry);
      video.removeEventListener('resize', updateCanvasGeometry);
      video.removeEventListener('loadeddata', updateCanvasGeometry);
      setIsCameraReady(false);
    };
  }, [videoRef, canvasRef, isCameraReady]);

  const memoizedStopDetection = useCallback(() => {
    console.log("ğŸ›‘ ì–¼êµ´ ì¸ì‹ ì¤‘ì§€ ìš”ì²­ (memoized)");
    setIsDetecting(false);
    isDetectingRef.current = false;
    if (detectionIntervalRef.current) clearInterval(detectionIntervalRef.current);
    detectionIntervalRef.current = null;
    if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    animationFrameRef.current = null;
    if (canvasRef.current) {
      const ctx = canvasRef.current.getContext('2d');
      if (ctx) {
        const cssDrawingWidth = parseFloat(canvasRef.current.style.width) || 0;
        const cssDrawingHeight = parseFloat(canvasRef.current.style.height) || 0;
        if (cssDrawingWidth > 0 && cssDrawingHeight > 0) {
            ctx.clearRect(0, 0, cssDrawingWidth, cssDrawingHeight);
        }
      }
    }
    lastFullDetectionsRef.current = [];
    frameCountRef.current = 0;
    setConsecutiveDrowsyFrames(0);
    setEarHistory([]);
    setAttentionHistory([]);
    // ê¹œë¹¡ì„ ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
    setBlinkTimestamps([]);
    setIsEyeClosed(false);
    setLastBlinkTime(0);
    smoothedBoxesRef.current.clear();
  }, [canvasRef]);

  useEffect(() => {
    const video = videoRef.current;
    if (video) {
      const handleStreamChange = () => {
        console.log("ğŸ“¹ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë³€ê²½ ê°ì§€ (loadeddata)");
        setIsCameraReady(false); 
        if (isDetectingRef.current) {
          memoizedStopDetection();
        }
      };
      video.addEventListener('loadeddata', handleStreamChange);
      return () => {
        video.removeEventListener('loadeddata', handleStreamChange);
      };
    }
  }, [videoRef, memoizedStopDetection]);

  useEffect(() => {
    const loadModels = async () => {
      try {
        console.log("ğŸ§  AI ëª¨ë¸ ë¡œë”© ì‹œì‘...");
        await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
        await faceapi.nets.faceExpressionNet.loadFromUri('/models');
        setIsModelLoaded(true); console.log("ğŸ¯ ëª¨ë“  AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!");
      } catch (error) {
        console.error("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:", error);
        setModelLoadingError("AI ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
        toast.error("AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      }
    };
    loadModels();
    return () => {
      if (detectionIntervalRef.current) clearInterval(detectionIntervalRef.current);
      if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    };
  }, []);
  
  const drawDetections = useCallback((
    canvas: HTMLCanvasElement,
    fullDetections: FullFaceDescriptionType[],
    videoForOriginalDimsRef: React.RefObject<HTMLVideoElement>
  ) => {
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const dpr = window.devicePixelRatio || 1;
    
    // ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ videoRefì—ì„œ í´ë¼ì´ì–¸íŠ¸ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    const videoElement = videoForOriginalDimsRef.current;
    if (!videoElement || videoElement.clientWidth === 0 || videoElement.clientHeight === 0) {
      console.warn("âš ï¸ drawDetections: ë¹„ë””ì˜¤ ìš”ì†Œê°€ ì—†ê±°ë‚˜ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤.", {
        hasVideoElement: !!videoElement,
        videoClientWidth: videoElement?.clientWidth,
        videoClientHeight: videoElement?.clientHeight,
        videoReadyState: videoElement?.readyState,
      });
      return;
    }

    const cssDrawingWidth = videoElement.clientWidth;
    const cssDrawingHeight = videoElement.clientHeight;

    const devicePixelRatio = window.devicePixelRatio || 1;

    // ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •
    canvas.width = canvas.offsetWidth * devicePixelRatio;
    canvas.height = canvas.offsetHeight * devicePixelRatio;
 
    // ìº”ë²„ìŠ¤ë¥¼ ì‹¤ì œ í¬ê¸°ë¡œ í™•ëŒ€ (scale() ì‚¬ìš©)
    ctx.scale(devicePixelRatio, devicePixelRatio);

    ctx.clearRect(0, 0, cssDrawingWidth, cssDrawingHeight);

    ctx.save();
    ctx.strokeStyle = 'rgba(255,0,0,0.5)';
    ctx.lineWidth = 1;
    ctx.strokeRect(0, 0, cssDrawingWidth, cssDrawingHeight);
    ctx.restore();

    if (fullDetections.length === 0) {
      const time = Date.now() / 1000;
      const pulseIntensity = 0.5 + 0.3 * Math.sin(time * 2);
      const guideWidth = Math.min(cssDrawingWidth * 0.6, 250);
      const guideHeight = guideWidth * 1.2;
      const guideX = (cssDrawingWidth - guideWidth) / 2;
      const guideY = (cssDrawingHeight - guideHeight) / 2;

      ctx.save();
      ctx.strokeStyle = `rgba(255, 255, 255, ${pulseIntensity * 0.6})`;
      ctx.lineWidth = 2 / dpr;
      ctx.setLineDash([10 / dpr, 5 / dpr]);
      ctx.strokeRect(guideX, guideY, guideWidth, guideHeight);
      ctx.restore();

      ctx.save();
      const cornerSize = 15;
      ctx.strokeStyle = `rgba(255, 255, 255, ${pulseIntensity})`;
      ctx.lineWidth = 3 / dpr;
      ctx.setLineDash([]);
      const corners = [
        [guideX, guideY], [guideX + guideWidth, guideY],
        [guideX, guideY + guideHeight], [guideX + guideWidth, guideY + guideHeight]
      ];
      corners.forEach(([xPos, yPos], i) => {
        ctx.beginPath();
        if (i === 0) { ctx.moveTo(xPos, yPos + cornerSize); ctx.lineTo(xPos, yPos); ctx.lineTo(xPos + cornerSize, yPos); }
        else if (i === 1) { ctx.moveTo(xPos, yPos + cornerSize); ctx.lineTo(xPos, yPos); ctx.lineTo(xPos - cornerSize, yPos); }
        else if (i === 2) { ctx.moveTo(xPos, yPos - cornerSize); ctx.lineTo(xPos, yPos); ctx.lineTo(xPos + cornerSize, yPos); }
        else { ctx.moveTo(xPos, yPos - cornerSize); ctx.lineTo(xPos, yPos); ctx.lineTo(xPos - cornerSize, yPos); }
        ctx.stroke();
      });
      ctx.restore();
      
      ctx.save();
      ctx.fillStyle = `rgba(255, 255, 255, ${pulseIntensity * 0.8})`;
      ctx.font = `16px -apple-system, BlinkMacSystemFont, sans-serif`;
      ctx.textAlign = 'center';
      ctx.textBaseline = 'middle';
      const textX = cssDrawingWidth / 2;
      const textY = guideY - 20;
      ctx.fillText('ì–¼êµ´ì„ í™”ë©´ì— ë§ì¶°ì£¼ì„¸ìš”', textX, textY);
      ctx.restore();
      return;
    }

    const displaySize = { width: cssDrawingWidth, height: cssDrawingHeight };

    if (!videoElement.videoWidth || !videoElement.videoHeight) {
      console.warn("âš ï¸ drawDetections: ì–¼êµ´ ë°•ìŠ¤ ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ ì›ë³¸ ë¹„ë””ì˜¤ í¬ê¸° ì •ë³´ ì—†ìŒ");
      return;
    }

    fullDetections.forEach((fullDescription, index) => {
      const detectionBox = fullDescription.detection.box;
      if (!detectionBox) return;

      const currentRect = new faceapi.Rect(detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height);
      let smoothedBox = currentRect;
      const previousSmoothedBox = smoothedBoxesRef.current.get(index);
      if (previousSmoothedBox) {
        smoothedBox = new faceapi.Rect(
          lerp(previousSmoothedBox.x, currentRect.x, SMOOTHING_FACTOR),
          lerp(previousSmoothedBox.y, currentRect.y, SMOOTHING_FACTOR),
          lerp(previousSmoothedBox.width, currentRect.width, SMOOTHING_FACTOR),
          lerp(previousSmoothedBox.height, currentRect.height, SMOOTHING_FACTOR)
        );
      }
      smoothedBoxesRef.current.set(index, smoothedBox);

      const scaleX = cssDrawingWidth / videoElement.videoWidth;
      const scaleY = cssDrawingHeight / videoElement.videoHeight;
      const x = smoothedBox.x * scaleX;
      const y = smoothedBox.y * scaleY;
      const width = smoothedBox.width * scaleX;
      const height = smoothedBox.height * scaleY;
      
      ctx.save();
      const cornerLineLength = 30;
      const cornerRadius = 8;
      ctx.strokeStyle = 'rgba(255, 255, 255, 0.9)';
      ctx.lineWidth = 4 / dpr;
      ctx.lineCap = 'round';
      ctx.lineJoin = 'round';
      const rectX = x; const rectY = y; const rectWidth = width; const rectHeight = height;
      const cornersForRect = [
        { x: rectX, y: rectY, type: 'topLeft' }, { x: rectX + rectWidth, y: rectY, type: 'topRight' },
        { x: rectX, y: rectY + rectHeight, type: 'bottomLeft' }, { x: rectX + rectWidth, y: rectY + rectHeight, type: 'bottomRight' }
      ];
      cornersForRect.forEach(corner => {
        ctx.beginPath();
        if (corner.type === 'topLeft') { ctx.moveTo(corner.x + cornerLineLength, corner.y); ctx.lineTo(corner.x + cornerRadius, corner.y); ctx.quadraticCurveTo(corner.x, corner.y, corner.x, corner.y + cornerRadius); ctx.lineTo(corner.x, corner.y + cornerLineLength); }
        else if (corner.type === 'topRight') { ctx.moveTo(corner.x - cornerLineLength, corner.y); ctx.lineTo(corner.x - cornerRadius, corner.y); ctx.quadraticCurveTo(corner.x, corner.y, corner.x, corner.y + cornerRadius); ctx.lineTo(corner.x, corner.y + cornerLineLength); }
        else if (corner.type === 'bottomLeft') { ctx.moveTo(corner.x, corner.y - cornerLineLength); ctx.lineTo(corner.x, corner.y - cornerRadius); ctx.quadraticCurveTo(corner.x, corner.y, corner.x + cornerRadius, corner.y); ctx.lineTo(corner.x + cornerLineLength, corner.y); }
        else { ctx.moveTo(corner.x, corner.y - cornerLineLength); ctx.lineTo(corner.x, corner.y - cornerRadius); ctx.quadraticCurveTo(corner.x, corner.y, corner.x - cornerRadius, corner.y); ctx.lineTo(corner.x - cornerLineLength, corner.y); }
        ctx.stroke();
      });
      ctx.restore();
      
      const resizedResult = faceapi.resizeResults(fullDescription, displaySize) as FullFaceDescriptionType;
      if (resizedResult && resizedResult.landmarks) {
        faceapi.draw.drawFaceLandmarks(canvas, resizedResult.landmarks);
      }
    });

    if (smoothedBoxesRef.current.size > fullDetections.length) {
      const newSmoothedBoxes = new Map<number, faceapi.Rect>();
      fullDetections.forEach((_, index) => {
        if (smoothedBoxesRef.current.has(index)) {
          newSmoothedBoxes.set(index, smoothedBoxesRef.current.get(index)!);
        }
      });
      smoothedBoxesRef.current = newSmoothedBoxes;
    }
  }, []);

  const startDetection = useCallback(() => {
    console.log("ğŸš€ startDetection í˜¸ì¶œë¨ - ìƒíƒœ í™•ì¸:", {
      isModelLoaded,
      isDetectingRef: isDetectingRef.current,
      isCameraReady,
      videoRef: !!videoRef.current,
      canvasRef: !!canvasRef.current,
      videoReadyState: videoRef.current?.readyState,
      videoWidth: videoRef.current?.videoWidth,
      videoHeight: videoRef.current?.videoHeight,
      videoClientWidth: videoRef.current?.clientWidth,
      videoClientHeight: videoRef.current?.clientHeight
    });

    if (!isModelLoaded) { 
      console.log("âŒ AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ");
      toast.error("AI ëª¨ë¸ ë¡œë”© í•„ìš”"); 
      return; 
    }
    if (isDetectingRef.current) { 
      console.log("âš ï¸ ì´ë¯¸ ê°ì§€ ì‹¤í–‰ ì¤‘"); 
      return; 
    }

    // isCameraReady ì²´í¬ë¥¼ ë” ìœ ì—°í•˜ê²Œ ë³€ê²½
    const video = videoRef.current;
    const canvas = canvasRef.current;
    
    if (!video || !canvas) {
      console.log("âŒ ë¹„ë””ì˜¤ ë˜ëŠ” ìº”ë²„ìŠ¤ ìš”ì†Œê°€ ì—†ìŒ");
      toast.error("ì¹´ë©”ë¼ ìš”ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨");
      return;
    }

    // ë¹„ë””ì˜¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì€ ê²½ìš° ëŒ€ê¸°
    if (video.readyState < 2) {
      console.log("â³ ë¹„ë””ì˜¤ ë¡œë”© ëŒ€ê¸° ì¤‘...", { readyState: video.readyState });
      setTimeout(() => startDetection(), 500);
      return;
    }

    // ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° í™•ì¸
    if (!video.videoWidth || !video.videoHeight) {
      console.log("â³ ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ëŒ€ê¸° ì¤‘...", { 
        videoWidth: video.videoWidth, 
        videoHeight: video.videoHeight 
      });
      setTimeout(() => startDetection(), 500);
      return;
    }

    console.log("âœ… ëª¨ë“  ì¡°ê±´ ì¶©ì¡±, ê°ì§€ ì‹œì‘");
    
    setIsDetecting(true);
    isDetectingRef.current = true;
    setLastDetectionTime(Date.now());
    frameCountRef.current = 0;

    let lastAnimateTime = 0;
    const animate = (currentTime: number) => {
      if (!isDetectingRef.current) return;
      animationFrameRef.current = requestAnimationFrame(animate);
      if (currentTime - lastAnimateTime < 16) return; // ì•½ 60fps
      lastAnimateTime = currentTime;
      if (canvasRef.current && showPreview) {
        drawDetections(canvasRef.current, lastFullDetectionsRef.current, videoRef);
      }
    };
    animationFrameRef.current = requestAnimationFrame(animate);

    detectionIntervalRef.current = setInterval(async () => {
      const video = videoRef.current;
      if (video && isDetectingRef.current && video.readyState >= video.HAVE_ENOUGH_DATA) {
        frameCountRef.current++;
        try {
          const detection = await faceapi
            .detectSingleFace(video, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.15 }))
            .withFaceLandmarks().withFaceExpressions();
          
          // ë‹¨ì¼ ê°ì§€ ê²°ê³¼ë¥¼ ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ì¡´ ë¡œì§ê³¼ í˜¸í™˜
          const detections: FullFaceDescriptionType[] = detection ? [detection] : [];
          lastFullDetectionsRef.current = detections;
          
          if (detection) {
            setLastDetectionTime(Date.now());
            const desc = detection;
            const { yaw, pitch, roll } = estimateHeadPose(desc.landmarks);
            const ear = (computeAdvancedEAR(desc.landmarks.getLeftEye()) + computeAdvancedEAR(desc.landmarks.getRightEye())) / 2;
            const mar = computeMAR(desc.landmarks.getMouth());
            const gaze = advancedGazeEstimation(desc.landmarks);
            const emotion = desc.expressions.asSortedArray()[0]?.expression || 'neutral';
            
            // ì‹¤ì œ ê¹œë¹¡ì„ ì¹´ìš´íŠ¸
            const blinkRate = detectBlink(ear);
            const { isDrowsyFromBlinks, blinkStatus } = assessDrowsinessFromBlinks(blinkRate);
            
            // ë””ë²„ê¹…: ì£¼ìš” ê°’ë“¤ ë¡œê·¸ (20í”„ë ˆì„ë§ˆë‹¤)
            if (frameCountRef.current % 20 === 0) {
              console.log("ğŸ” ì–¼êµ´ ë¶„ì„ ê²°ê³¼:", {
                frame: frameCountRef.current,
                ear: ear.toFixed(3),
                mar: mar.toFixed(3),
                blinkRate,
                blinkStatus,
                isDrowsyFromBlinks,
                emotion,
                leftEyeEAR: computeAdvancedEAR(desc.landmarks.getLeftEye()).toFixed(3),
                rightEyeEAR: computeAdvancedEAR(desc.landmarks.getRightEye()).toFixed(3)
              });
            }
            
            // ê¸°ì¡´ ì¡¸ìŒ ê°ì§€ ë¡œì§ê³¼ ê¹œë¹¡ì„ ê¸°ë°˜ ì¡¸ìŒ ê°ì§€ ê²°í•©
            const isDrowsyFromEyes = ear < 0.20;
            const isDrowsyFromMouth = mar > 0.4;
            const isDrowsyFromHead = Math.abs(pitch) > 25;
            
            const isDrowsy = isDrowsyFromEyes || isDrowsyFromMouth || isDrowsyFromHead || isDrowsyFromBlinks;
            
            if (isDrowsy) setConsecutiveDrowsyFrames(prev => prev + 1); else setConsecutiveDrowsyFrames(0);
            const newEarHistory = [...earHistory, ear].slice(-30);
            setEarHistory(newEarHistory);
            
            const attentionScore = calculateAttentionScore(ear, mar, { yaw, pitch, roll }, gaze, blinkRate);
            const fatigueLevel = assessFatigueLevel(attentionScore, ear, consecutiveDrowsyFrames);
            const newAttentionHistory = [...attentionHistory, attentionScore].slice(-60);
            setAttentionHistory(newAttentionHistory);
            onFaceDetected({
              isDrowsy, isAttentive: attentionScore > 70, emotion, ear, mar, 
              gazeDirection: gaze, headPose: { yaw, pitch, roll }, 
              blinkRate, attentionScore, fatigueLevel, confidence: Math.round(desc.detection.score * 100)
            });
          } else {
            lastFullDetectionsRef.current = [];
            if (Date.now() - lastDetectionTime > 5000) {
              onFaceNotDetected(); setLastDetectionTime(Date.now());
            }
          }
        } catch (err) { console.error("ì–¼êµ´ ë¶„ì„ ì˜¤ë¥˜:", err); }
      }
    }, 150);
  }, [isModelLoaded, isCameraReady, showPreview, onFaceDetected, onFaceNotDetected, videoRef, canvasRef, earHistory, attentionHistory, drawDetections, memoizedStopDetection, detectBlink, assessDrowsinessFromBlinks]);
  
  const lerp = (start: number, end: number, t: number) => start * (1 - t) + end * t;
  const SMOOTHING_FACTOR = 0.2;

  return {
    isModelLoaded,
    isDetecting,
    isCameraReady,
    startDetection,
    stopDetection: memoizedStopDetection,
    modelLoadingError
  };
};

